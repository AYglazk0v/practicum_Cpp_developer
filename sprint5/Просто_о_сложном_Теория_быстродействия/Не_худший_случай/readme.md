<details>
<summary>Теория + тестирование:</summary>

# Не худший случай

Чтобы оценить, сколько примерно времени будет работать ваш алгоритм, ориентируйтесь на правило: ядро процессора выполняет около миллиарда действий в секунду. Оценка грубая, но в некоторых случаях она полезна. Количество действий можно посчитать теоретически. Разберёмся, всегда ли теория верна.

В начале темы мы рассмотрели функцию, которая определяет, одинаковые ли элементы в двух векторах. Вспомним код:

```cpp
// O(n²)
bool TestPermut(const vector<int>& v1, const vector<int>& v2) {
    // если они разной длины, элементы заведомо разные
    if (v1.size() != v2.size()) {
        return false;
    }

    for (int i : v1) {
        // проверяем, что каждый элемент первого вектора
        // содержится одинаковое количество раз в обоих векторах
        if (count(v1.begin(), v1.end(), i) != count(v2.begin(), v2.end(), i)) {
            return false;
        }
    }

    return true;
}

// O(n log n)
bool TestPermut2(const vector<int>& v1, const vector<int>& v2) {
    auto v1_copy = v1;
    auto v2_copy = v2;

    std::sort(v1_copy.begin(), v1_copy.end());
    std::sort(v2_copy.begin(), v2_copy.end());

    return v1_copy == v2_copy;
}

```

Возможно, вы обратили внимание на странный момент: наивный квадратичный алгоритм из условия быстро завершался при первом запуске, но для ответа  `true`  ему нужно было много времени. А второй алгоритм всегда работает примерно одинаково быстро. Сравним алгоритмы на сильно различающихся векторах из 500 000 элементов:

```
O(n²): 2 ms
O(n log n): 181 ms

```

Может показаться, что теория обманывает. Сделаем векторы похожими:

```cpp
int main() {
    std::mt19937 g;

    // ...

    v2 = v1;
    shuffle(v2.begin(), v2.end(), g);
    v2[rand() % v2.size()]++;

    // ...
}

```

Различие только в одном элементе со случайным индексом. Результаты работы:

```
O(n²): 2286 ms
O(n log n): 178 ms

```

На этот раз всё как и должно быть.

----------

Почему так происходит?

-   Мы делали заполнение случайными числами, поэтому первый алгоритм работает случайное время — то быстро, то медленно.
    
-   Приведённые оценки сложности — это оценки худшего случая. Но не любой случай худший: для первого алгоритма различие между худшим и лучшим прослеживается более ярко, чем для второго.
    
-   O(N^2) будет хуже O(N\log N) уже при не очень больших N, порядка сотен. А в нашем случае векторы были по 500 000 элементов.
    

Если векторы существенно отличаются, первый алгоритм быстро найдёт элемент, который есть в первом векторе, но отсутствует во втором. После этого алгоритм сразу завершится. Но для ответа  `true`  ему понадобится много времени. А второй, быстрый алгоритм будет в любом случае выполнять две сортировки — в этом смысле он более стабильный.

----------

Подобный эффект можно наблюдать и с  `upper_bound`. В уроке о логарифме вы увидели, что этот алгоритм сильно выигрывает у  `find_if`. Посмотрим, всегда ли. Вернёмся к тому примеру, но теперь вместо 500 000 000 будем искать число, превышающее 100:

```cpp
...
int result_number;
{
    LOG_DURATION("std::upper_bound"s);
    for (int i = 0; i < SEARCHES; ++i) {
        auto iter = upper_bound(nums.begin(), nums.end(), 100);
        result_number = *iter;
    }
}
cout << result_number << endl;

{
    LOG_DURATION("std::find_if"s);
    for (int i = 0; i < SEARCHES; ++i) {
        auto iter = find_if(nums.begin(), nums.end(), [](int x) {
            return x > 100;
        });
        result_number = *iter;
    }
}
cout << result_number << endl;
...

```

Результат может быть таким:

```cpp
std::upper_bound: 58 ms
352
std::find_if: 0 ms
352

```

Оба алгоритма выдали одинаковый результат, но  `find_if`  сделал это гораздо быстрее вопреки теории.

----------

Как вы думаете, почему в этом случае  `find_if`  оказался быстрее, несмотря на то, что его сложность больше?

-   Теория гарантирует преимущество меньшей сложности только при больших N, здесь оно недостаточно велико.
    
-   Сложность  `upper_bound`  — это O(\log N), а логарифм сложная вещь — алгоритм будет работать то быстро, то медленно.
    
-   Сложность  `find_if`  — это O(N) в худшем случае. Но тут повезло: случай оказался далеко не самым худшим для этого алгоритма.
    

Проходя вектор,  `find_if`  быстро находит нужное число, в то время как  `upper_bound`  в любом случае будет сходиться к нему бинарным поиском. Однако это не значит, что нужно всегда использовать  `find_if`  — в среднем  `upper_bound`  гораздо быстрее.

----------

Из этих примеров можно сделать важный вывод: теоретическая оценка даёт верхнюю границу сложности, но иногда она слишком груба. Надо принимать во внимание специфику задачи.

</details>

<details>
<summary>Ответы:</summary>

# Ответы на задания

Почему так происходит?

-   **(-)**  Мы делали заполнение случайными числами, поэтому первый алгоритм работает случайное время — то быстро, то медленно.

> Отчасти верно, но эффект наблюдается при разных запусках с разными случайными числами, и объяснение явно не случайное.

-   **(+)**  Приведённые оценки сложности — это оценки худшего случая. Но не любой случай худший: для первого алгоритма различие между худшим и лучшим прослеживается более ярко, чем для второго.

> Верно!

-   **(-)**  O(N^2) будет хуже O(N\log N) уже при не очень больших N, порядка сотен. А в нашем случае векторы были по 500 000 элементов.

----------

Как вы думаете, почему в этом случае  `find_if`  оказался быстрее, несмотря на то, что его сложность больше?

-   **(-)**  Теория гарантирует преимущество меньшей сложности только при больших N, здесь оно недостаточно велико.

> Как видно из предыдущих примеров, N=1\ 000\ 000 вполне достаточно. Логарифм показывает хорошее преимущество при гораздо меньших N.

-   **(-)**  Сложность  `upper_bound`  — это O(\log N), а логарифм сложная вещь — алгоритм будет работать то быстро, то медленно.

> Как раз  `upper_bound`  ведёт себя стабильно, работая каждый раз примерно одинаковое время. А вот про  `find_if`  такого сказать нельзя.

-   **(+)**  Сложность  `find_if`  — это O(N) в худшем случае. Но тут повезло: случай оказался далеко не самым худшим для этого алгоритма.

</details>

<details>
<summary>Задание:</summary>

### Задание

В большом сортированном векторе  `v`  хранятся случайные числа в диапазоне от нуля до  `n`. Причём все числа встречаются с одинаковой вероятностью. Требуется оценить, сколько точно чисел не превышают заданного числа  `i`.

В этой задаче вы сможете заранее выяснить, будет случай худшим или нет. Скомбинируйте два алгоритма, чтобы всегда оставаться в выигрыше:

-   в хорошем случае применяйте линейный  `find_if`;
-   в среднем и плохом — логарифмический  `upper_bound`.

Хорошим будет считаться случай, когда ожидаемый ответ не превышает числа  `log2(v.size())`. Для вычисления границы используйте функцию  `log2`  из библиотеки  `<cmath>`.

Реализуйте функцию  `int EffectiveCount(const vector<int>& v, int n, int i)`. Она принимает отсортированный по возрастанию вектор  `v`, содержащий случайные числа от нуля до  `n`. Функция должна вычислять количество чисел в  `v`, не превышающих  `i`. При этом в  `cout`  должен выдаваться текст  `Using find_if`  либо  `Using upper_bound`  в зависимости от того, какой алгоритм вы выбрали.

### Ограничения

Не меняйте сигнатуру функции  `EffectiveCount`. Для отделения хорошего случая от остальных используйте порог, описанный в условии.

### Пример

Пусть дан вектор из 10000 элементов с числами от 0 до 4999. Требуется найти количество чисел, не превышающих 5. Так как возможных чисел 5000, каждое число встречается в среднем 2 раза. Ожидаемый ответ — 12, так как нас устраивают 6 чисел. Двоичный логарифм числа 10000 примерно равен 13,3, так что выбираем  `find_if`.

Если требуется найти числа до 100, то ожидаемый ответ 202 и мы выбираем  `upper_bound`.

### Что отправлять на проверку

Включите в решение реализацию  `EffectiveCount`. Функция  `main`  учитываться не будет.

### Как будет тестироваться ваш код

Будет проверено, что  `EffectiveCount`  правильно находит ответ. Также будет проверено, что она делает это достаточно быстро и пользуется нужным алгоритмом.

### Подсказка

-   Нужно найти позицию первого числа, большего  `i`. Номер этой позиции будет совпадать с количеством чисел, не превышающих  `i`.
-   Добавьте  `if`, который позволит выбрать между  `find_if`  и  `upper_bound`.
-   Чтобы оценить ожидаемый ответ, вычислите, какая доля чисел будет меньше, либо равна  `i`. Это можно сделать по формуле:  `static_cast<int64_t>(v.size())*(i + 1)/(n + 1)`. Здесь потребовалось преобразование к  `int64_t`  — так можно избежать переполнений.
-   Найдя итератор алгоритмом  `find_if`  или  `upper_bound`, возвратите разность между ним и  `v.begin()`.

</details>
