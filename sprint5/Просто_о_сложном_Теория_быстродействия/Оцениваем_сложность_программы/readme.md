<details>
<summary>Теория:</summary>

# Оцениваем сложность программы

Считать рукопожатия интересно, но мы занимаемся программированием, поэтому будем считать и оценивать количество операций. Сначала нужно понять, от чего оно зависит. Для многих функций стандартной библиотеки количество операций уже оценено до нас, и эту оценку можно найти в документации. В уроке посмотрим, как ей пользоваться.

Скорость роста количества операций программы называют  **асимптотической сложностью**, но мы будем говорить просто «сложность программы».

Количество операций зависит от различных факторов. Прежде всего определитесь, что именно измерять: отдельную функцию, алгоритм, уже реализованный в C++, или всю программу целиком. Затем подумайте, от каких параметров зависит количество операций, и как их измерить.

Параметром может быть число, которое вводит пользователь, или размер массива, переданного функции. Если речь идёт об алгоритме, обрабатывающем элементы контейнера между двумя итераторами, важной мерой будет расстояние между этими итераторами — количество шагов от начального до конечного. В операциях с  `vector`,  `deque`,  `map`,  `set`  часто имеет значение количество элементов, уже находящихся в контейнере, или расстояние от элемента, над которым производится операция, до конца контейнера. Действие с одним элементом контейнера нередко выполняется за O(1) операций.

Узнать сложность стандартного алгоритма C++ или метода контейнера можно из документации на сайте  [cppreference.com](https://cppreference.com/).

Мы рассматривали выражения, которые сводились к O(N), O(N^2). Однако в реальности количество операций может зависеть не от одного параметра, а от нескольких. Выражения могут усложняться, но вычислять через O всё равно гораздо проще, чем напрямую.

Вспомните первое правило асимптотики — убрать всё лишнее, оставить под O только главное. Теперь вы готовы к тому, чтобы узнать второе:

> Второе правило асимптотики: оценивать худший случай.

При вставке в начало вектора количество операций варьировалось от 1 до N. Итоговую сложность мы оценили как O(N^2). Если бы мы сразу рассмотрели худший случай, когда в векторе уже N элементов, можно было оценить сложность одной вставки как O(N). Тогда для вычисления не пришлось бы даже вспоминать формулу прогрессии: мы сделали N раз по O(N) операций и получили O(N^2). А это правильный ответ.

Если бы мы были оптимистами и оценивали лучший случай — одна операция при вставке — полученная оценка O(N) не отражала бы реальность. Учитывая одну только сложность, определить разницу между вставками в начало и в конец не вышло бы.

Иногда оценка худшего случая — это не выбор, а необходимость. Например, когда сложность какой-либо операции неизвестна. Перемешаем числа 1, 2, …, r случайным образом и поищем число r/2:

```cpp
#include <algorithm>
#include <iostream>
#include <numeric>
#include <vector>
#include <random>

using namespace std;

int main() {
    int r;
    cin >> r;

    vector<int> v(r);

    std::mt19937 g;

    // 1. заполним числами от 1 до r и 
    iota(v.begin(), v.end(), 1);

    // 2. перемешаем их случайным образом
    shuffle(v.begin(), v.end(), g);

    // 3. ищем число r / 2
    int pos = find(v.begin(), v.end(), r / 2) - v.begin();
    cout << r / 2 << " находится на позиции "s << pos << endl;
}

```

В программе сразу три алгоритма:  `iota`,  `shuffle`  и  `find`. Чтобы оценить её сложность, обратимся к документации.

----------

Изучите раздел «Сложность» на  [странице алгоритма iota](https://ru.cppreference.com/w/cpp/algorithm/iota)  и оцените сложность операции заполнения из примера.

-   O(1)
    
-   O®
    
-   O(r^2)
    

В документации сказано, что алгоритм выполнит в точности  `last - first`  инкрементов и присваиваний. Это означает, что количество операций будет O(N), где N — расстояние между итераторами. В нашем случае расстояние между итераторами — это  `r`, поэтому оценим сложность как O®.

----------

Изучите раздел «Сложность» на  [странице алгоритма  `shuffle`](https://ru.cppreference.com/w/cpp/algorithm/random_shuffle)  и дайте оценку сложности операции перемешивания из примера.

-   O(1)
    
-   O®
    
-   O(r^2)
    

[Страница алгоритма`shuffle`](https://en.cppreference.com/w/cpp/algorithm/random_shuffle)  уже не даёт точной оценки. Она утверждает, что сложность алгоритма линейна, то есть O(N), где N опять же расстояние между итераторами, равное в нашем случае  `r`.

----------
Найдите документацию по алгоритму  `find`  и дайте оценку сложности поиска.

-   O(1)
    
-   O®
    
-   O(r^2)
    

Опять O®, но на  [странице алгоритма](https://en.cppreference.com/w/cpp/algorithm/find)  третий вариант — это не более  `last - first`  применений предиката  `p`. Предикат применяют для  `find_if`, в обычном  `find`  предикатом считается сравнение  `==`. Как и раньше,  `last - first`  — это расстояние между итераторами,  `r`  в нашем случае. Но обратите внимание на слова «не более». Это значит, что алгоритм может завершиться и быстрее, если число нашлось сразу. Действительно,  `r/2`  могло случайно оказаться в начале контейнера. Тогда  `find`  быстро его найдёт и завершит работу. Но мы оцениваем худший случай. Поэтому нужно оценить этот этап так, как если бы число попало в конец.

Во всех трёх случаях документация говорила разное, а оценка получилась одинаковой — O®.

----------

Оценка худшего случая — это не каприз. Есть минимум три причины выбирать именно худший случай:

1.  Так проще оценивать. Например, в нашем случае невозможно предсказать, сколько точно шагов сделает  `find`.
2.  Нежелательно, когда программа обычно работает быстро, но при случайном стечении обстоятельств вдруг подвисает.
3.  Программа с плохой сложностью может подвисать не случайно, а при специально подобранных входных данных. Этим могут воспользоваться злоумышленники.

Иногда оценивают среднюю сложность — усреднённое количество операций, которое делает программа. Эта оценка, как правило, труднее, но именно её используют в некоторых алгоритмах.

Мы оценили не все операции. В программе есть ввод из  `cin`, инициализация переменных, вывод в  `cout`, не говоря уже о том, что сама программа при запуске требует инициализации операционной системой. Но все эти операции — константные, они не зависят от размера введённого числа  `r`. Зависеть могут ввод и вывод, но количество цифр 32-битного целого числа никогда не превышает 11. По первому правилу оценки оставляем только главное — три алгоритма, имеющие сложность O®. Нетрудно понять, что все они в сумме будут эквивалентны одному O®. Подробнее это разберём в уроке об арифметике сложности.

</details>

<details>
<summary>Ответы:</summary>

# Ответы на задания

Изучите раздел «Сложность» на  [странице алгоритма iota](https://ru.cppreference.com/w/cpp/algorithm/iota)  и оцените сложность операции заполнения из примера.

-   **(-)**  O(1)
    
-   **(+)**  O®
    
-   **(-)**  O(r^2)
    

----------

Изучите раздел «Сложность» на  [странице алгоритма  `shuffle`](https://ru.cppreference.com/w/cpp/algorithm/random_shuffle)  и дайте оценку сложности операции перемешивания из примера.

-   **(-)**  O(1)
    
-   **(+)**  O®
    
-   **(-)**  O(r^2)
    

----------

Найдите документацию по алгоритму  `find`  и дайте оценку сложности поиска.

-   **(-)**  O(1)
    
-   **(+)**  O®
    
-   **(-)**  O(r^2)

</details>
